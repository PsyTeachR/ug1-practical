[
["index.html", "Level 1 Data Skills Course Information", " Level 1 Data Skills 2019-2020 Course Information Hello and welcome to Level 1 Psychology at the University of Glasgow! This is the course book for Psych 1A and Psych 1B and will contain almost everything you need for the practical element of the course. We say almost because there’s some stuff that we need to host on Moodle for admin reasons, for example, resources related to the lectures and assignment submission links. However, for labs and coursework you should keep this book very close. In fact, it would be a very good idea to save a bookmark for this page to your phone and computer. For a more general overview of the course including contact details for key staff, University rules and regulations, and how your final course grade will be calculated, please refer to the Level 1 handbook. "],
["a-lab-1.html", "1 1A: Lab 1 1.1 Pre-class activities 1.2 In-class activities 1.3 Homework", " 1 1A: Lab 1 In this lab you will be introduced to the skills you will develop over the next year and beyond. This lab will introduce open science and why it is relevant to your development as a Psychologist. You will meet your groups and the staff that will be leading your labs and who you will get to know well over the two semesters. We can’t wait to get started! 1.1 Pre-class activities Before we get started learning about psychology, it’s useful to do a few admin jobs to make sure that you’re getting all the information you need and the best experience possible. 1.1.1 Activity 1: Make sure you know your University username and password and have your student ID card. This may seem overly simple however, there’s nothing worse than turning up to a lab and not being able to access the computers. Make sure that you know your username and password and consider using a password manager so that you don’t need to remember it yourself. If something has gone wrong and your account isn’t working or if you’ve forgotten your password you can find the IT help support for students here. You will also need to bring your student card to the labs as we will scan it to take attendance. If you have lost your card you can find out how to get a replacement here. 1.1.2 Activity 2: Set-up your university e-mail on your phone Setting up your University e-mail on your phone is one of the most important things you can do to make sure you know what is going on. When we contact you, it will be through your University e-mail, and when you contact us you should use this e-mail so that we can verify your identity. Please do not use your personal gmail/hotmail etc. e-mail addresses. You need to make sure that you check your e-mail at least once a day. Failing to read the information we send you is not a valid excuse for missing something so if you have your email on your phone with push notifications enabled it makes it much more likely that you will do this. You can find instructions for how to set up your email on your phone here. You may find that you get a lot of e-mails as you progress through University. Please do not turn off your e-mail or turn off e-mails from Moodle because you will miss information. Instead, you can use folders and rules to help organise your inbox (e.g., you can set a rule that all emails from a mailing list go to a specific folder rather than your inbox to help keep things tidy). 1.1.3 Activity 3: Be social If you have a Twitter or Facebook account you may find it helpful to follow the School accounts. On Facebook we have a Level 1 group so that you can contact other students. On Twitter, you can follow the School of Psychology account, but many of your 1st year lecturers and GTAs are also active on Twitter and you may find it interesting to follow them as well - Emily Nordmann, Niamh Stack, Heather Cleland-Woods, Helena Paterson, Holly Scott, Steven McNair, Jude Stevenson, Carolina Kuepper-Tetzel. Ok, let’s start talking about psychology. 1.1.4 The replication crisis There is an ongoing debate within Psychology regarding whether the discipline is experiencing a replication crisis. When we say replication we mean the extent to which consistent results are obtained when we repeat an experiment under comparable conditions. So, when we say replication crisis we mean that efforts to replicate past study findings often do not show the same results. For example, in 2015, a team of researchers examined social science experiments published in the academic journals Nature and Science between 2010 and 2015. Out of 21 experiments, 13 were successfully replicated. Why is this happening? When conducting research, you have to ask yourself a lot of questions: How many participants will I recruit? What variables am I interested in? What’s the best way to analyse my data? This is called researcher degrees of freedom. This means researchers often have a lot of flexibility and can approach data in a “have a look” manner. Crucially, researcher degrees of freedom can lead to researchers using questionable research practices such as: Failing to report all of a study’s dependent measures (e.g what you measure in the experiment) Collecting more data after peeking at your results in order to make your results turn out the way you wanted Failing to report all conditions in a study (e.g. Collecting data from three conditions - no/low/high anxiety - but only reporting two) Stopping data collection earlier than planned because you found results you wanted Only reporting studies that “worked” HARKing - Hypothesising After Results Are Known (e.g. claiming you predicted these results before collecting data) In some cases, researchers have even been known to falsify their data. A related concept is reproducibility. If research is reproducible it means someone else could take the information provided by the authors (e.g., data, method section, analysis code) and reproduce their results. This may sound like it should be easy enough to do, but as you’ll learn about in class and throughout the lectures, this is very difficult, partially because often researchers have not shared their data or code. Why should I care? Science does not occur in a vacuum. Work that is published and disseminated then goes on to influence public knowledge (e.g. through reporting in the media) and the decisions our politicians make every day. What can be done about it? During your time here at Glasgow, we will support you in developing skills and experience in open science practices. Open science practices are actions which aim to improve the transparency, accessibility, and reproducibility of scientific research. 1.1.5 Activity 4: Open science video Watch this video of Dr Simine Vazire talking about open science and why it is an important concept for us to understand in Psychology. 1.1.5.1 Additional resources around open science and reproducibility Is most published research wrong? Replicability and Reproducibility Debate with Professor Dorothy Bishop Why an Entire Field of Psychology Is in Trouble Beyond Cherry-picking by Amy Orben 1.2 In-class activities All of the slides that are presented in the Labs are available on the Psych 1A Moodle page. 1.2.1 Activity 5: Getting to know the data This semester we will use the same dataset each week to develop our skills and knowledge. The dataset is from Woodworth et al. (2018). You can download all the files here and you can find an explanation of the data here Web-based Positive Psychology Interventions: A Reexamination of Effectiveness. Take some time now to read through the study and familiarise yourself with the data you will be using over the coming weeks. 1.2.1.1 How to use zip files In this course we will often ask you to download a folder with multiple files and this will be stored on the server as a zip file. A zip file is a folder that contains files that have been compressed to make the file size smaller and enables you to download multiple files at once, however, before you use the files from a zip folder you first need to extra them. Click on the link to download the folder and select to save the zip file in your lab 1 folder. Navgiate to the zip file and open it. You will see all the files it contains but don’t use these - click “Extract all” on the top ribbon. You will be asked to select a location to save the unzipped files. Normally the default location it suggests will be the same folder and so you can just click “Extract”. You can now delete the zip file and use the unzipped files. This is a really important step - if you use the compressed files this will not work properly. Figure 1.1: Unzipping a folder Pause and test your knowledge! When you get the correct answer, the answer box will turn green. Sometimes this doesn’t work on Internet Explorer or Edge so be sure to use Chrome or Firefox. How many questionnaire variables are in the dataset? 2 4 3 What does the AHI measure? (Hint, use a single word) What does the CES-D measure? (hint, use a single word) In groups, have a think about what a possible research question might look like. How would you use this data? Would you be interested in studying any other variables alongside the data that you have? 1.3 Homework For the homework this week, we will go over some basic programming concepts and terminology, common pitfalls, helpful hints, and where to get help. Those of you who have no programming experience should find this chapter particularly helpful, however, even if you’ve used R before there may be some helpful hints and tips so please make sure you read through this chapter before the lab. You do not need to formally submit this homework but we will check that you’ve done it in the next lab! This is a long chapter but we don’t expect you to memorise all the information that is contained in it and some sections of it will make not make sense until you start writing your own code in the lab - just make sure you know what help is available! 1.3.1 Why are you teaching me programming?? I signed up for psychology not computer science!! Research methods and statistics is a large part of doing a psychology degree. In fact, it’s so important for your understanding of psychology that it’s one of the core areas that the British Psychological Society require for you to graduate with an accredited degree. Unfortunately, many students don’t realise that this is a part of psychology until the first week of lectures and for some people it comes as a bit of a shock. But! There is no need to worry. With both statistics and programming we’re going to start from the very beginning and develop your skills slowly over the next three years. The skills that you learn from this course will allow you to read research papers, design, conduct and analyse both qualitative and quantitative studies, evaluate research in all its forms (even fake news), and make some pretty fancy visualisations. Even if you don’t plan on a career in research, the transferable skills that you develop from this course will make you an employable and versitile graduate. The reason that we’re going to teach you how to do statistics and manage data using R is because of the issues we’ve been discussing regarding replication and reproducibility. Writing code is essentially like writing a fool-proof recipe. You can give other people (or just you after a long holiday) your raw data and code and they’ll be able to see exactly what you did, step-by-step with nothing missing. R is just the tool we will use to teach you how to do reproducible science so that you won’t make the same mistakes we did and so that psychological research will keep on improving. Right. Let’s begin. 1.3.2 R and R Studio For this course, you need two different bits of software, R and RStudio. R is a programming language that you will write code in and R Studio is an Integrated Development Environment (IDE) which makes working with R easier. Think of it as knowing English and using a plain text editor like NotePad to write a book versus using a word processor like Microsoft Word. You could do it, but it wouldn’t look as good and it would be much harder without things like spell-checking and formatting. In a similar way, you can use R without R Studio but we wouldn’t recommend it. The key thing to remember is that although you will do all of your work using R Studio for this course, you are actually using two pieces of software which means that from time-to-time, both of them may have separate updates. All of the University of Glasgow computers should already have R and R Studio installed, however, both are freely available so you may wish to install them on your own machine. There is a useful guide to installing them both here that you can use but if you need help wih this you can attend one of the PAL sessions or practice sessions (check your e-mails for details of when these run). 1.3.3 Getting to know R Studio R Studio has a console that you can try out code in (appearing as the bottom left window in Figure 1.2), there is a script editor (top left), a window showing functions and objects you have created in the “Environment” tab (top right window in the figure), and a window that shows plots, files packages, and help documentation (bottom right). Figure 1.2: RStudio interface You will learn more about how to use the features included in R Studio throughout this course, however, we highly recommend watching RStudio Essentials 1 from the R Studio team. The video lasts ~30 minutes and gives a tour of the main parts of R Studio. 1.3.4 Functions and arguments Functions in R execute specific tasks and normally take a number of arguments (if you’re into linguistics you might want to think as these as verbs that require a subject and an object). You can look up all the arguments that a function takes by using the help documentation by using the format ?function. Some arguments are required, and some are optional. Optional arguments will often use a default (normally specified in the help documentation) if you do not enter any value. As an example, let’s look at the help documentation for the function rnorm() which randomly generates a set of numbers with a normal distribution. 1.3.5 Activity 1: Open up R Studio and in the console, type the following code: ?rnorm The help documentation for rnorm() should appear in the bottom right help panel. In the usage section, we see that rnorm() takes the following form: rnorm(n, mean = 0, sd = 1) In the arguments section, there are explanations for each of the arguments. n is the number of observations we want to create, mean is the mean of the data points we will create and sd is the standard deviation of the set. In the details section it notes that if no values are entered for mean and sd it will use a default of 0 and 1 for these values. Because there is no default value for n it must be specified otherwise the code won’t run. Let’s try an example and just change the required argument n to ask R to produce 5 random numbers. 1.3.6 Activity 2: Copy and paste the following code into the console. set.seed(12042016) rnorm(n = 5) ## [1] -0.2896163 -0.6428964 0.5829221 -0.3286728 -0.5110101 These numbers have a mean of 0 and an SD of 1. Now we can change the additional arguments to produce a different set of numbers. rnorm(n = 5, mean = 10, sd = 2) ## [1] 13.320853 9.377956 10.235461 9.811793 13.019102 This time R has still produced 5 random numbers, but now this set of numbers has a mean of 10 and an sd of 2 as specified. Always remember to use the help documentation to help you understand what arguments a function requires. If you’re looking up examples of code online, you may often see code that starts with the function set.seed(). This function controls the random number generator - if you’re using any functions that generate numbers randomly (such as rnorm()), running set.seed() will ensure that you get the same result (in some cases this may not be what you want to do). We call set.seed() in this example because it means that you will get the same random numbers as this book. 1.3.7 Argument names In the above examples, we have written out the argument names in our code (e.g., n, mean, sd), however, this is not strictly necessary. The following two lines of code would both produce the same result (although each time you run rnorm() it will produce a slightly different set of numbers, because it’s random, but they would still have the same mean and SD): rnorm(n = 6, mean = 3, sd = 1) rnorm(6, 3, 1) Importantly, if you do not write out the argument names, R will use the default order of arguments, that is for rnorm it will assume that the first number you enter is n. the second number is mean and the third number is sd. If you write out the argument names then you can write the arguments in whatever order you like: rnorm(sd = 1, n = 6, mean = 3) When you are first learning R, you may find it useful to write out the argument names as it can help you remember and understand what each part of the function is doing. However, as your skills progress you may find it quicker to omit the argument names and you will also see examples of code online that do not use argument names so it is important to be able to understand which argument each bit of code is referring to (or look up the help documentation to check). In this course, we will always write out the argument names the first time we use each function, however, in subsequent uses they may be omitted. 1.3.8 Tab auto-complete One very useful feature of R Studio is the tab auto-complete for functions (see Figure 1.3). If you write the name of the function and then press the tab key, R Studio will show you the arguments that function takes along with a brief description. If you press enter on the argument name it will fill in the name for you, just like auto-complete on your phone. This is incredibly useful when you are first learning R and you should remember to use this feature frequently. Figure 1.3: Tab auto-complete 1.3.9 Base R and packages When you install R you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation are typically referred to as Base R and there is a useful cheat sheet that shows many Base R functions here. However, the power of R is that it is extendable and open source - put simply, if a function doesn’t exist or doesn’t work very well, anyone can create a new package that contains data and code to allow you to perform new tasks. You may find it useful to think of Base R as the default apps that come on your phone and packages as additional apps that you need to download separately. 1.3.10 Installing and loading packages All of the University of Glasgow computers will already have all of the packages you need for this course so you only need to install packages if you are using your own machine. Please do not install any packages on the university machines. 1.3.11 Activity 3: Install the tidyverse In order to use a package, you must first install it. The following code installs the package tidyverse, a package we will use very frequently in this course. If you are working on your own computer, use the below code to install the tidyverse. Do not do this if you are working on a University machine. install.packages(&quot;tidyverse&quot;) You only need to install a package once, however, each time you start R you need to load the packages you want to use, in a similar way that you need to install an app on your phone once, but you need to open it every time you want to use it. To load packages we use the function library(). Typically you would start any analysis script by loading all of the packages you need, but we will come back to that in the labs. 1.3.12 Activity 4: Load the tidyverse Run the below code to load the tidyverse. You can do this regardless of whether you are using your own computer or a University machine. library(tidyverse) Now that we’ve loaded the tidyverse package we can use any of the functions it contains but remember, you need to run the library() function every time you start R. 1.3.13 Package updates In addition to updates to R and R Studio, the creators of packages also sometimes update their code. This can be to add functions to a package, or it can be to fix errors. One thing to avoid is unintentionally updating an installed package. When you run install.packages() it will always install the latest version of the package and it will overwrite any older versions you may have installed. Sometimes this isn’t a problem, however, sometimes you will find that the update means your code no longer works as the package has changed substantially. It is possible to revert back to an older version of a package but try to avoid this anyway. To avoid accidentally overwriting a package with a later version, you should never include install.packages() in your analysis scripts in case you, or someone else runs the code by mistake. Remember, the University of Glasgow computers will already have all of the packages you need for this course so you only need to install packages if you are using your own machine. 1.3.14 Package conflicts There are thousands of different R packages with even more functions. Unfortunately, sometimes different packages have the same function names. For example, the packages dplyr and MASS both have a function named select(). If you load both of these packages, R will produce a warning telling you that there is a conflict. library(dplyr) library(MASS) ## Warning: package &#39;MASS&#39; was built under R version 3.6.1 ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select In this case, R is telling you that the function select() in the dplyr package is being hidden (or ‘masked’) by another function with the same name. If you were to try and use select(), R would use the function from the package that was loaded most recently - in this case it would use the function from MASS. If you want to specify which package you want to use for a particular function you can use code in the format package::function, for example: dplyr::select() MASS::select() 1.3.15 Objects A large part of your coding will involve creating and manipulating objects. Objects contain stuff. That stuff can be numbers, words, or the result of operations and analyses.You assign content to an object using &lt;-. 1.3.16 Activity 5: Create some objects Copy and paste the following code into the console, change the code so that it uses your own name and age and run it. You should see that name, age, today, new_year, and data appear in the environment pane. name &lt;- &quot;emily&quot; age &lt;- 15 + 18 today &lt;-Sys.Date() new_year &lt;- as.Date(&quot;2020-01-01&quot;) data &lt;- rnorm(n = 10, mean = 15, sd = 3) Figure 1.4: Objects in the environment Note that in these examples, name,age, and new_year would always contain the values emily, 33, and the date of New Year’s Day 2020, however, today will draw the date from the operating system and data will be a randomly generated set of data so the values of these objects will not be static. As a side note, if you ever have to teach programming and statistics, don’t use your age as an example because you’ll have to update your teaching materials and it will make you feel old. Importantly, objects can be involved in calculations and can interact with each other. For example: age + 10 new_year - today mean(data) ## [1] 43 ## Time difference of 96 days ## [1] 17.66644 Finally, you can store the result of these operations in a new object: decade &lt;- age + 10 You may find it helpful to read &lt;- as contains, e.g., name contains the text emily. You will constantly be creating objects throughout this course and you will learn more about them and how they behave as we go along, however, for now it is enough to understand that they are a way of saving values, that these values can be numbers, text, or the result of operations, and that they can be used in further operations to create new variables. You may also see objects referred to as ‘variables’. There is a difference between the two in programming terms, however, they are used synonymously very frequently. 1.3.17 Looking after the environment If you’ve been writing a lot of code you may find that the environment pane (or workspace) has become cluttered with many objects. This can make it difficult to figure out which object you need and therefore you run the risk of using the wrong data frame. If you’re working on a new dataset, or if you’ve tried lots of different code before getting the final version, it is good practice to remember to clear the environment to avoid using the wrong object. You can do this in several way. To remove individual objects, you can type rm(object_name) in the console. Try this now to remove one of the objects you created in the previous section. To clear all objects from the environment run rm(list = ls()) in the console. To clear all objects from the environment you can also click the broom icon in the environment pane. Figure 1.5: Clearing the workspace 1.3.18 Setting the working directory What this means is that we need to tell R where the files we need are located. Think of it just like when you have different subjects, and you have seperate folders for each topic e.g. biology, history and so on. When working on R, it’s useful to have all the data sets and files you need in one folder. To set the working directory press session -&gt; set working directory -&gt; choose directory and then select the folder where the data sets we are working on are saved, and save this file in the same folder as well. In other words- make sure your data sets and scripts are all in the same folder. In the labs, we recommend that you create a folder for Psychology labs with sub-folders within for each lab in your M: drive. This is your personal area on the University network that is safe and secure so is much better than flashdrives or desktops. You can access your M drive by logging into any computer on the University network. Figure 1.6: Setting your working directory 1.3.19 Activity 6: Set the working directory Create new folders for each of the labs and then, following the above instructions, set your working directory to your Lab 1 folder. 1.3.20 R sessions When you open up R and start writing code, loading packages, and creating objects, you’re doing so in a new session. In addition to clearing the workspace, it can sometimes be useful to start a new session. This will happen automatically each time you start R, however, if you find your code isn’t working and you can’t figure out why, it might be worth starting a new session. This will clear the environment and detach all loaded packages - think of it like restarting your phone. To do this, click ‘Session - Restart R’. Remember that you will then need to load the packages you need and your data again. Figure 1.7: The truth about programming 1.3.21 Help and additional resources Figure 1.8: The truth about programming Getting good at programming really means getting good trying stuff out, searching for help online, and finding examples of code to copy. If you are having difficulty with any of the exercises contained in this book then you can ask for help on Slack or Moodle, however, learning to problem-solve effectively is a key skill that you need to develop throughout this course. Use the help documentation. If you’re struggling to understand how a function works, remember the ?function command. If you get an error message, copy and paste it in to Google - it’s very likely someone else has had the same problem. In addition to these course materials there are a number of excellent resources for learning R: R Cookbook StackOverflow R for Data Science Search or use the #rstats hashtag on Twitter 1.3.22 Debugging tips A large part of coding is trying to figure why your code doesn’t work and this is true whether you are a novice or an expert. As you progress through this course you should keep a record of mistakes you make and how you fixed them. In each chapter we will provide a number of common mistakes to look out for but you will undoubtedly make (and fix!) new mistakes yourself. Have you loaded the correct packages for the functions you are trying to use? One very common mistake is to write the code to load the package, e.g., library(tidyverse) but then forget to run it. Have you made a typo? Remember data is not the same as DATA and t.test is not the same as t_test. Is there a package conflict? Have you tried specifying the package and function with package::function? Is it definitely an error? Not all red text in R means an error - sometimes it is just giving you a message with information. 1.3.23 Activity 7: Test yourself Question 1. Why should you never include the code install.packages() in your analysis scripts? You should use library() instead Packages are already part of Base R You (or someone else) may accidentally install a package update that stops your code working You already have the latest version of the package Explain This Answer Remember, when you run install.packages() it will always install the latest version of the package and it will overwrite any older versions of the package you may have installed. Question 2.What will the following code produce? rnorm(6, 50, 10) A dataset with 10 numbers that has a mean of 6 and an SD of 50 A dataset with 6 numbers that has a mean of 50 and an SD of 10 A dataset with 50 numbers that has a mean of 10 and an SD of 6 A dataset with 50 numbers that has a mean of 10 and an SD of 6 Explain This Answer The default form for rnorm() is rnorm(n, mean, sd). If you need help remembering what each argument of a function does, look up the help documentation by running ?rnorm Question 3. If you have two packages that have functions with the same name and you want to specify exactly which package to use, what code would you use? package::function function::package library(package) install.packages(package) Explain This Answer You should use the form package::function, for example dplyr::select. Remember that when you first load your packages R will warn you if any functions have the same name - remember to look out for this! Question 4. Which of the following is most likely to be an argument? 35 read_csv() &lt;- Question 5. An easy way to spot functions is to look for brackets numbers computers. Question 6. The job of &lt;- is to send the output from the function to a/an argument assignment object. "],
["a-lab-2.html", "2 1A: Lab 2 2.1 Pre-class activities 2.2 In-class activities 2.3 Homework instructions", " 2 1A: Lab 2 2.1 Pre-class activities There are eight activities in total for this pre-class, but don’t worry, they are broken down into very small steps! 2.1.1 Activity 1: Create the working directory If you want to load data into R, or save the output of what you’ve created (which you almost always will want to do), you first need to tell R where the working directory is. All this means is that we tell R where the files we need (such as raw data) are located and where we want to save any files you have created. Think of it just like when you have different subjects, and you have separate folders for each topic e.g. biology, history and so on. When working with R, it’s useful to have all the data sets and files you need in one folder. We recommend making a new folder called “Level 1” with sub-folders for each lab and saving any data, scripts, and homework files for each lab in these folders. We suggest that you create this folder on the M: drive. This is your personal area on the University network that is safe and secure so it is much better than flashdrives or desktops. Figure 2.1: Folder structure First, choose a location for your lab work and then create the necessary folders for all five Psych 1A labs. 2.1.2 Activity 2: Set the working directory Once you have created your folders, open R Studio. To set the working directory click Session -&gt; Set Working Directory -&gt; Choose Directory and then select the Lab 2 folder as your working directory. Figure 2.2: Setting the working directory 2.1.3 R Markdown for lab work and homework assignments For the lab work and homework you will use a worksheet format called R Markdown (abbreviated as Rmd) which is a great way to create dynamic documents with embedded chunks of code. These documents are self-contained and fully reproducible (if you have the necessary data, you should be able to run someone else’s analyses with the click of a button) which makes it very easy to share. This is an important part of your open science training as one of the reasons we are using R Studio is that it enables us to share open and reproducible information. Using these worksheets enables you to keep a record of all the code you write during the labs, and when it comes time for the portfolio assignments, we can give you a task you can and then fill in the required code. For more information about R Markdown feel free to have a look at their main webpage sometime http://rmarkdown.rstudio.com. The key advantage of R Markdown is that it allows you to write code into a document, along with regular text, and then knit it using the package knitr to create your document as either a webpage (HTML), a PDF, or Word document (.docx). 2.1.4 Activity 3: Open and save a new R Markdown document To open a new R Markdown document click the ‘new item’ icon and then click ‘R Markdown’. You will be prompted to give it a title, call it “Lab 2”. Also, change the author name to your GUID as this will be good practice for the homework. Keep the output format as HTML. Once you’ve opened a new document be sure to save it by clicking File -&gt; Save as. Name this file “Pre-class”. If you’ve set the working directory correctly, you should now see this file appear in your file viewer pane. Figure 2.3: Opening a new R Markdown document 2.1.5 Activity 4: Create a new code chunk When you first open a new R Markdown document you will see a bunch of welcome text that looks like this: Figure 2.4: New R Markdown text Do the following steps: * Delete everything below line 7 * On line 8 type “About me” * Click Insert -&gt; R Your Markdown document should now look something like this: Figure 2.5: New R chunk What you have created is a code chunk. In R Markdown, anything written in the white space is regarded as normal text, and anything written in a grey code chunk is assumed to be code. This makes it easy to combine both text and code in one document. When you create a new code chunk you should notice that the grey box starts and ends with three back ticks ```. One common mistake is to accidentally delete these back ticks. Remember, code chunks are grey and text entry is white - if the colour of certain parts of your Markdown doesn’t look right, check that you haven’t deleted the back ticks. 2.1.6 Activity 5: Write some code Now we’re going to use the code examples you read about in Lab 1 to add some simple code to our R Markdown document. In your code chunk write the below code but replace the values of name/age/birthday with your own details). Note that text values and dates need to be contained in quotation marks but numerical values do not. Missing and/or unnecessary quotation marks are a common cause of code not working - remember this! name &lt;- &quot;Emily&quot; age &lt;- 34 today &lt;- Sys.Date() next_birthday &lt;- as.Date(&quot;2020-07-11&quot;) 2.1.7 Running code When you’re working in an R Markdown document, there are several ways to run your lines of code. First, you can highlight the code you want to run and then click Run -&gt; Run Selected Line(s), however this is very slow. Figure 2.6: Slow method of running code Alternatively, you can press the green “play” button at the top-right of the code chunk and this will run all lines of code in that chunk. Figure 2.7: Slightly better method of running code Even better though is to learn some of the keyboard shortcuts for R Studio. To run a single line of code, make sure that the cursor is in the line of code you want to run (it can be anywhere) and press ctrl + enter. If you want to run all of the code in the code chunk, press ctrl + shift + enter. Learn these shortcuts, they will make your life easier! 2.1.8 Activity 6: Run your code Run your code using one of the methods above. You should see the variables name, age, today, and next_birthday appear in the environment pane. 2.1.9 Activity 7: Inline code An incredibly useful feature of R Markdown is that R can insert values into your writing using inline code. If you’ve ever had to copy and paste a value or text from one file in to another, you’ll know how easy it can be to make mistakes. Inline code avoids this. It’s easier to show you what inline code does rather than to explain it so let’s have a go. First, copy and paste this text exactly (do not change anything) to the white space underneath your code chunk. My name is `r name` and I am `r age` years old. It is `r next_birthday - today` days until my birthday. 2.1.10 Activity 8: Knitting your file Nearly finished! As our final step we are going to “knit” our file. This simply means that we’re going to compile our code into a document that is more presentable. To do this click Knit -&gt; Knit to HMTL. R Markdown will create a new HTML document and it will automatically save this file in your working directory. As if by magic, that slightly odd bit of text you copied and pasted now appears as a normal sentence with the values pulled in from the objects you created. My name is Emily and I am 34 years old. It is 288 days until my birthday. We’re not going to use this function very often in the rest of the course but hopefully you can see just how useful this would be when writing up a report with lots of numbers! R Markdown is an incredibly powerful and flexible format - this book was written using it! If you want to push yourself with R, additional functions and features of R Markdown would be a good place to start. Before we finish, there are a few final things to note about knitting that will be useful for the homework: R Markdown will only knit if your code works - this is a good way of checking for the portfolio assignments whether you’ve written legal code! You can choose to knit to a Word document rather than HTML. This can be useful for e.g., sharing with others, however, it may lose some functionality and it probably won’t look as good so we’d recommend always knitting to HTML. You can choose to knit to PDF, however, this requires an LaTex installation and is quite complicated. If you don’t already know what LaTex is and how to use it, do not knit to PDF. If you do know how to use LaTex, you don’t need us to give you instructions! R will automatically open the knitted HTML file in the viewer, however, you can also navigate to the folder it is stored in and open the HTML file in your web browser (e.g., Chrome or Firefox). 2.1.11 Finished And you’re done! On your very first time using R you’ve not only written functioning code but you’ve written a reproducible output! You could send someone else your R Markdown document and they would be able to produce exactly the same HTML document as you, just by pressing knit. The key thing we want you to take away from this pre-class is that R isn’t scary. It might be very new to a lot of you, but we’re going to take you through it step-by-step. You’ll be amazed at how quickly you can start producing professional-looking data visualisations and analysis. 2.2 In-class activities 2.2.1 Activity 1: APA referencing Look at the following reference and answer the below questions: Smith, M. K., Wood, W. B., Adams, W. K., Wieman, C., Knight, J. K., Guild, N., &amp; Su, T. T. (2009). Why peer discussion improves student performance on in-class concept questions. Science, 323(5910), 122-124. https://doi.org/10.1126/science.1165919 How many authors are there? What is the name of the journal? How many pages is the article? According to APA style: The title of the paper should be In bold text In italics In normal text. When using a direct in-text citation you should use and &amp; to connect the names of the authors. When citing a paper with multiple authors, if there are fewer than six authors the first time you cite the paper in the essay you should Write out all of the names Use et al. 2.2.2 Data skills Part of becoming a psychologist is asking questions and gathering data to enable you to answer these questions effectively. It is very important that you understand all aspects of the research process such as experimental design, ethics, data management and visualisation. In this class, you will continue to develop reproducible scripts. This means scripts that completely and transparently perform an analysis from start to finish in a way that yields the same result for different people using the same software on different computers. And transparency is a key value of science, as embodied in the “trust but verify” motto. When you do things reproducibly, others can understand and check your work. This benefits science, but there is a selfish reason, too: the most important person who will benefit from a reproducible script is your future self. When you return to an analysis after two weeks of vacation, you will thank your earlier self for doing things in a transparent, reproducible way, as you can easily pick up right where you left off. As part of your skill development, it is important that you work with data so that you can become confident and competent in your management and analysis of data. In the labs, we will work with real data that has been shared by other researchers. 2.2.3 Getting data ready to work with Today in the lab you will learn how to load the packages required to work with our data. You’ll then load the data into R Studio before getting it organised into a sensible format that relates to our research question. If you can’t remember what packages are, go back and revise 1.3.9. 2.2.4 Activity 2: Set-up Before we begin working with the data we need to do some set-up. If you need help with any of these steps, you should refer to Chapter 2.1: Download the lab 2 files, extract the files and then move them in to your Lab 2 folder. Open R and ensure the environment is clear. Set the working directory to your Lab 2 folder. Open the stub-2.2.Rmd file and ensure that the working directory is set to your Lab 2 folder and that the two .csv data files are in your working directory (you should see them in the file pane). 2.2.5 Activity 3: Load in the package Today we need to use the tidyverse package. You will use this package in every single lab on this course as the functions it contains are those we use for data wrangling, descriptive statistics, and visualisation. To load the tidyverse type the following code into your code chunk (not the console) and then run it. library(tidyverse) 2.2.6 Open data For this lab we are going to be using the real dataset that you looked at in Lab 1. Click the below link if you want a refresher of what the dataset contains. Woodworth, R.J., O’Brien-Malone, A., Diamond, M.R. and Schüz, B., 2018. Data from, ‘Web-based Positive Psychology Interventions: A Reexamination of Effectiveness’. Journal of Open Psychology Data, 6(1). 2.2.7 Activity 4: Read in data Now we can read in the data. To do this we will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in .xlsx files and other formats, however in this course we will only use .csv files. First, we will create an object called dat that contains the data in the ahi-cesd.csv file. Then, we will create an object called info that contains the data in the participant-info.csv. dat &lt;- read_csv (&quot;ahi-cesd.csv&quot;) pinfo &lt;- read_csv(&quot;participant-info.csv&quot;) There is also a function called read.csv(). Be very careful NOT to use this function instead of read_csv() as they have different ways of naming columns. For the home, unless your results match ours exactly you will not get the marks which means you need to be careful to use the right functions. 2.2.8 Activity 5: Check your data You should now see that the objects dat and pinfo have appeared in the environment pane. Whenever you read data into R you should always do an initial check to see that your data looks like you expected. There are several ways you can do this, try them all out to see how the results differ. In the environment pane, click on dat and pinfo. This will open the data to give you a spreadsheet-like view (although you can’t edit it like in Excel) In the environment pane, click the small blue play button to the left of dat and pinfo. This will show you the structure of the object information including the names of all the variables in that object and what type they are (also see str(pinfo)) Use summary(pinfo) Use head(pinfo) Just type the name of the object you want to view, e.g., dat. 2.2.9 Activity 6: Join the files together We have two files, dat and info but what we really want is a single file that has both the data and the demographic information about the participants. R makes this very easy by using the function inner_join(). Remember to use the help function ?inner_join if you want more information about how to use a function and to use tab auto-complete to help you write your code. The below code will create a new object all_dat that has the data from both dat and pinfo and it will use the columns id and intervention to match the participants’ data. Run this code and then view the new dataset using one of the methods from Activity 4. all_dat &lt;- inner_join(x = dat, # the first table you want to join y = pinfo, # the second table you want to join by = c(&quot;id&quot;, &quot;intervention&quot;)) # columns the two tables have in common 2.2.10 Activity 7: Pull out variables of interest Our final step is to pull our variables of interest. Very frequently, datasets will have more variables and data than you actually want to use and it can make life easier to create a new object with just the data you need. In this case, the file contains the responses to each individual question on both the AHI scale and the CESD scale as well as the total score (i.e., the sum of all the individual responses). For our analysis, all we care about is the total scores, as well as the demographic information about participants. To do this we use the select() function to create a new object named summarydata. summarydata &lt;- select(.data = all_dat, # name of the object to take data from ahiTotal, cesdTotal, sex, age, educ, income, occasion,elapsed.days) # all the columns you want to keep Run the above code and then run head(summarydata). If everything has gone to plan it should look something like this: ahiTotal cesdTotal sex age educ income occasion elapsed.days 32 50 1 46 4 3 5 182.03 34 49 1 37 3 2 2 14.19 34 47 1 37 3 2 3 33.03 35 41 1 19 2 1 0 0.00 36 36 1 40 5 2 5 202.10 37 35 1 49 4 1 0 0.00 2.2.11 Activity 8: Visualise the data As you’re going to learn about more over this course, data visualisation is extremely important. Visualisations can be used to give you more information about your dataset, but they can also be used to mislead. We’re going to look at how to write the code to produce simple visualisations in Lab 3 and Lab 4, for now, we want to focus on how to read and interpret different kinds of graphs. Please feel free to play around with the code and change TRUE to FALSE and adjust the values and labels and see what happens but do not worry about understanding the code. Just copy and paste it. Copy, paste and run the below code to produce a bar graph that shows the number of female and male participants in the dataset. ggplot(summarydata, aes(x = as.factor(sex), fill = as.factor(sex))) + geom_bar(show.legend = FALSE, alpha = .8) + scale_x_discrete(name = &quot;Sex&quot;) + scale_fill_viridis_d(option = &quot;E&quot;) + scale_y_continuous(name = &quot;Number of participants&quot;)+ theme_minimal() Are there more male or more female participants (you will need to check the codebook to find out what 1 and 2 mean to answer this)? More female participants More male participants Copy, paste, and run the below code to create violin-boxplots of happiness scores for each income group. ggplot(summarydata, aes(x = as.factor(income), y = ahiTotal, fill = as.factor(income))) + geom_violin(trim = FALSE, show.legend = FALSE, alpha = .4) + geom_boxplot(width = .2, show.legend = FALSE, alpha = .7)+ scale_x_discrete(name = &quot;Income&quot;, labels = c(&quot;Below Average&quot;, &quot;Average&quot;, &quot;Above Average&quot;)) + scale_y_continuous(name = &quot;Authentic Happiness Inventory Score&quot;)+ theme_minimal() + scale_fill_viridis_d() The violin (the wavy line) shows density. Basically, the fatter the wavy shape, the more data points there are at that point. It’s called a violin plot because it very often looks (kinda) like a violin. The boxplot is the box in the middle. The black line shows the median score in each group. The median is calculated by arranging the scores in order from the smallest to the largest and then selecting the middle score. The other lines on the boxplot show the interquartile range. There is a really good explanation of how to read a boxplot here. The black dots are outliers, i.e., extreme values. Which income group has the highest median happiness score? Below average Average Above average Which income group has the lowest median happiness score? Below average Average How many outliers does the Average income group have? Finally, try knitting the file to HTML. And that’s it, well done! Remember to save your Markdown in your Lab 2 folder and make a note of any mistakes you made and how you fixed them. 2.2.11.1 Finished! Well done! You have started on your journey to become a confident and competent member of the open scientific community! To show us how competent you are you should now complete the homework for this lab which follows the same instructions as this in-class activity but asks you to work with different variables. Always use the lab prep materials as well as what you do in class to help you complete the class assessments! 2.2.12 Debugging tips When you downloaded the files from Moodle did you save the file names exactly as they were originally? If you download the file more than once you will find your computer may automatically add a number to the end of the file name. data.csv is not the same as data(1).csv. Pay close attention to names! Have you used the exact same object names as we did in each activity? Remember, name is different to Name. In order to make sure you can follow along with this book, pay special attention to ensuring you use the same object names as we do. Have you used quotation marks where needed? Have you accidentally deleted any back ticks (```) from the beginning or end of code chunks? 2.2.13 Test yourself When loading in a .csv file, which function should you use? read_csv() read.csv() Explain this answer Remember, in this course we use read_csv() and it is important for the homework that you use this function otherwise you may find that the variable names are slightly different and you won’t get the marks The function inner_join() takes the arguments x, y, by. What does by do? Specifies the first table to join Specifies the second table to join Specifies the column to join by that both tables have in common What does the function select() do? Keeps only the observations you specify Keeps only the variables you specify Keeps only the objects you specify 2.3 Homework instructions Just like you did in the pre-class, we’re going to use R Markdown for the homework sheets. If you haven’t done the pre-class, please work through it before attempting the homework. There are just a couple of important rules we need you to follow to make sure this all runs smoothly. These worksheets need to you fill in your answers and not change any other information. For example, if we ask you to replace NULL with your answer, only write in the code you are giving as your answer and nothing else. To illustrate - Task 1 read in your data data &lt;- NULL The task above is to read in the data file we are using for this task - the correct answer is data &lt;- read_csv(data.csv). You would replace the NULL with: Solution to Task 1 data &lt;- read_csv(&quot;data.csv&quot;) This means that we can look for your code and if it is in the format we expect to see it in, we can give you the marks! If you decide to get all creative on us then we can’t give you the marks as ‘my_lab_Nov_2018.csv’ isn’t the filename we have given to you to use. So don’t change the file, variable or data frame names as we need these to be consistent. We will look for your answers within the boxes which start and end with ``` and have {r task name} in them e.g. ```{r tidyverse, messages=FALSE} library(tidyverse) ``` These are called code chunks and are the part of the worksheet that we can read and pick out your answers. If you change these in any way we can’t read your answer and therefore we can’t give you marks. You can see in the example above that the code chunk (the grey zone), starts and ends with these back ticks (usually found on top left corner of the keyboard). This code chunk has the ticks and text which makes it the part of the worksheet that will contain code. The {r tidyverse} part tells us which task it is (e.g., loading in tidyverse) and therefore what we should be looking for and what we can give marks for - loading in the package called tidyverse in the example above. If this changes then it won’t be read properly, so will impact on your grade. The easiest way to use our worksheets is to think of them as fill-in-the-blanks and keep the file names and names used in the worksheet the same. If you are unsure about anything then use the forums on Moodle and Slack to ask any questions and come along to the practice sessions. 2.3.1 Homework files You can download all the R homework files and Assessment Information you need from the Lab Homework section of the Psych 1A Moodle. . "],
["a-lab-3.html", "3 1A: Lab 3 3.1 Pre-class activities 3.2 In-class activities 3.3 Homework", " 3 1A: Lab 3 In lab 2, you were introduced to the R environment (e.g. setting your working directory and the difference between .R and .Rmd files). You also began working with messy data by having a go at loading in datasets using read_csv(), joined files together using inner_join(), and pulled out variables of interest using select(). In lab 3, we’ll be moving on to becoming familiar with the Wickham Six and the functionality of the R package, tidyverse! 3.1 Pre-class activities Data comes in lots of different formats. One of the most common formats is that of a two-dimensional table (the two dimensions being rows and columns). Usually, each row stands for a separate observation (e.g. a subject), and each column stands for a different variable (e.g. a response, category, or group). A key benefit of tabular data is that it allows you to store different types of data-numerical measurements, alphanumeric labels, categorical descriptors-all in one place. It may surprise you to learn that scientists actually spend far more time cleaning and preparing their data than they spend actually analysing it. This means completing tasks such as cleaning up bad values, changing the structure of tables, merging information stored in separate tables, reducing the data down to a subset of observations, and producing data summaries. Some have estimated that up to 80% of time spent on data analysis involves such data preparation tasks (Dasu &amp; Johnson, 2003)! Many people seem to operate under the assumption that the only option for data cleaning is the painstaking and time-consuming cutting and pasting of data within a spreadsheet program like Excel. We have witnessed students and colleagues waste days, weeks, and even months manually transforming their data in Excel, cutting, copying, and pasting data. Fixing up your data by hand is not only a terrible use of your time, but it is error-prone and not reproducible. Additionally, in this age where we can easily collect massive datasets online, you will not be able to organise, clean, and prepare these by hand. In short, you will not thrive as a psychologist if you do not learn some key data wrangling skills. Although every dataset presents unique challenges, there are some systematic principles you should follow that will make your analyses easier, less error-prone, more efficient, and more reproducible. In this lesson you will see how data science skills will allow you to efficiently get answers to nearly any question you might want to ask about your data. By learning how to properly make your computer do the hard and boring work for you, you can focus on the bigger issues. 3.1.1 Tidyverse Tidyverse (https://www.tidyverse.org/) is a collection of R packages created by world-famous data scientist Hadley Wickham. Tidyverse contains six core packages: dplyr, tidyr, readr, purrr, ggplot2, and tibble. Last week when you typed library(tidyverse) into R, you will have seen that it loads in all of these packages in one go. Within these six core packages, you should be able to find everything you need to wrangle and visualise your data. In this chapter, we are going to focus on the dplyr package, which contains six important functions: select() Include or exclude certain variables (columns) filter() Include or exclude certain observations (rows) mutate() Create new variables (columns) arrange() Change the order of observations (rows) group_by() Organize the observations into groups summarise() Derive aggregate variables for groups of observations These six functions are known as ’single table verbs’ because they only operate on one table at a time. Although the operations of these functions may seem very simplistic, it’s amazing what you can accomplish when you string them together: Hadley Wickham has claimed that 90% of data analysis can be reduced to the operations described by these six functions. Again, we don’t expect you to remember everything in this pre-class - the important thing is that you know where to come and look for help when you need to do particular tasks. Being good at coding really is just being good at knowing what to copy and paste. 3.1.2 The babynames database To demonstrate the power of the six dplyr verbs, we will use them to work with the babynames data from the babynames package. The babynames dataset has historical information about births of babies in the U.S. 3.1.3 Activity 1: Set-up Do the following. If you need help, consult the Lab 2 materials. Download the lab 3 files, extract the files and then move them in to your Lab 3 folder. Open R Studio and ensure the environment is clear. Open the stub-3.1.Rmd file and ensure that the working directory is set to your Lab 3 folder and that the two .csv data files are in your working directory (you should see them in the file pane). If you are working on your own computer, install the package babynames. Remember, never install packages if you are working on a university computer. The university computers will already have this package installed. Type and run the code that loads the packages tidyverse and babynames using library() in the Activity 1 code chunk. library(tidyverse) library(babynames) 3.1.4 Activity 2: Look at the data The package babynames contains an object of the same name that contains all the data about babynames. View a preview of this dataset by typing babynames in to the console. You should see the following output: babynames ## # A tibble: 1,924,665 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 ## 2 1880 F Anna 2604 0.0267 ## 3 1880 F Emma 2003 0.0205 ## 4 1880 F Elizabeth 1939 0.0199 ## 5 1880 F Minnie 1746 0.0179 ## 6 1880 F Margaret 1578 0.0162 ## 7 1880 F Ida 1472 0.0151 ## 8 1880 F Alice 1414 0.0145 ## 9 1880 F Bertha 1320 0.0135 ## 10 1880 F Sarah 1288 0.0132 ## # ... with 1,924,655 more rows The first line tells us that the object we are looking at is in a tibble with information on five variables with over 1.9 million rows. Yes, this dataset contains 1.8 million observations. Interested in analyzing these data by hand? No thanks! A tibble is basically a table of data presenting a two dimensional array of your data. Each row in the table represents data about births for a given name and sex in a given year. The variables are: variable type description year double (numeric) year of birth sex character recorded sex of baby (F = female, M = male) name character forename given to baby n integer number of babies given that name prop double (numeric) proportion of all babies of that sex The first row of the table tells us that in the year 1880, there were 7065 baby girls born in the U.S. who were given the name Mary, and this accounted for about 7% of all baby girls. 3.1.5 Activity 3: Data visualisation Type the code below into a new code chunk and run it. We’re going to cover how to write visualisation code in Lab so still don’t worry about not understanding the plot code yet. The point is show you how much you can accomplish with very little code. The code creates a graph showing the popularity of four girl baby names - Alexandra, Beverly, Emily, and Kathleen - from 1880 to 2014. You should see Figure 3.1 appear, which shows the proportion of each name across different years - you can plug in different names if you like and see how the plot changes. dat &lt;- babynames %&gt;% filter(name %in% c(&quot;Emily&quot;,&quot;Kathleen&quot;,&quot;Alexandra&quot;,&quot;Beverly&quot;), sex==&quot;F&quot;) ggplot(data = dat,aes(x = year,y = prop, colour=name))+ geom_line() Figure 3.1: Proportion of four baby names from 1880 to 2014 3.1.6 Activity 4: Selecting variables of interest There are two numeric measurements of name popularity, prop (the proportion of all babies with each name) is probably more useful than n (total number of babies with that name), because it takes into account that different numbers of babies are born in different years. Just like in Lab 2, if we wanted to create a dataset that only includes certain variables, we can use the select() function from the dplyr package. Run the below code to only select the columns year, sex, name and prop. select(.data = babynames, # the object you want to select variables from year, sex, name, prop) # the variables you want to select ## # A tibble: 1,924,665 x 4 ## year sex name prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1880 F Mary 0.0724 ## 2 1880 F Anna 0.0267 ## 3 1880 F Emma 0.0205 ## 4 1880 F Elizabeth 0.0199 ## 5 1880 F Minnie 0.0179 ## 6 1880 F Margaret 0.0162 ## 7 1880 F Ida 0.0151 ## 8 1880 F Alice 0.0145 ## 9 1880 F Bertha 0.0135 ## 10 1880 F Sarah 0.0132 ## # ... with 1,924,655 more rows Alternatively, you can also tell R which variables you don’t want, in this case, rather than telling R to select year, sex, name and prop, we can simply tell it to drop the column n using the minus sign - before the variable name. select(.data = babynames, -n) ## # A tibble: 1,924,665 x 4 ## year sex name prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1880 F Mary 0.0724 ## 2 1880 F Anna 0.0267 ## 3 1880 F Emma 0.0205 ## 4 1880 F Elizabeth 0.0199 ## 5 1880 F Minnie 0.0179 ## 6 1880 F Margaret 0.0162 ## 7 1880 F Ida 0.0151 ## 8 1880 F Alice 0.0145 ## 9 1880 F Bertha 0.0135 ## 10 1880 F Sarah 0.0132 ## # ... with 1,924,655 more rows Note that select() does not change the original tibble, but makes a new tibble with the specified columns. If you don’t save this new tibble to an object, it won’t be saved. If you want to keep this new dataset, create a new object. When you run this code, you will see your new tibble appear in the environment pane. new_dat &lt;- select(.data = babynames, -n) 3.1.7 Activity 5: Arranging the data The function arrange() will sort the rows in the table according to the columns you supply. Try running the following code: arrange(.data = babynames, # the data you want to sort name) # the variable you want to sort by ## # A tibble: 1,924,665 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2007 M Aaban 5 0.00000226 ## 2 2009 M Aaban 6 0.00000283 ## 3 2010 M Aaban 9 0.00000439 ## 4 2011 M Aaban 11 0.00000542 ## 5 2012 M Aaban 11 0.00000543 ## 6 2013 M Aaban 14 0.00000694 ## 7 2014 M Aaban 16 0.00000783 ## 8 2015 M Aaban 15 0.00000736 ## 9 2016 M Aaban 9 0.00000446 ## 10 2017 M Aaban 11 0.0000056 ## # ... with 1,924,655 more rows The data are now sorted in ascending alphabetical order by name. The default is to sort in ascending order. If you want it descending, wrap the name of the variable in the desc() function. For instance, to sort by year in descending order, run the following code: arrange(babynames,desc(year)) ## # A tibble: 1,924,665 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2017 F Emma 19738 0.0105 ## 2 2017 F Olivia 18632 0.00994 ## 3 2017 F Ava 15902 0.00848 ## 4 2017 F Isabella 15100 0.00805 ## 5 2017 F Sophia 14831 0.00791 ## 6 2017 F Mia 13437 0.00717 ## 7 2017 F Charlotte 12893 0.00688 ## 8 2017 F Amelia 11800 0.00629 ## 9 2017 F Evelyn 10675 0.00569 ## 10 2017 F Abigail 10551 0.00563 ## # ... with 1,924,655 more rows You can also sort by more than one column. What do you think the following code will do? arrange(babynames, desc(year), desc(sex), desc(prop)) 3.1.8 Activity 6: Using filter to select observations We have previously used select() to select certain variables or columns, however, frequently you will also want to select only certain observations or rows, for example, only babies born after 1999, or only babies named “Mary”. You do this using the verb filter(). The filter() function is a bit more involved than the other verbs, and requires more detailed explanation, but this is because it is also extremely powerful. Here is an example of filter, can you guess what it will do? filter(.data = babynames, year &gt; 2000) The first part of the code tells the function to use the object babynames. The second argument, year &gt; 2000, is what is known as a Boolean expression: an expression whose evaluation results in a value of TRUE or FALSE. What filter() does is include any observations (rows) for which the expression evaluates to TRUE, and exclude any for which it evaluates to FALSE. So in effect, behind the scenes, filter() goes through the entire set of 1.8 million observations, row by row, checking the value of year for each row, keeping it if the value is greater than 2000, and rejecting it if it is less than 2000. To see how a boolean expression works, consider the code below: years &lt;- 1996:2005 years years &gt; 2000 ## [1] 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE You can see that the expression years &gt; 2000 returns a logical vector (a vector of TRUE and FALSE values), where each element represents whether the expression is true or false for that element. For the first five elements (1996 to 2000) it is false, and for the last five elements (2001 to 2005) it is true. Here are the most commonly used Boolean expressions. Operator Name is TRUE if and only if A &lt; B less than A is less than B A &lt;= B less than or equal A is less than or equal to B A &gt; B greater than A is greater than B A &gt;= B greater than or equal A is greater than or equal to B A == B equivalence A exactly equals B A != B not equal A does not exactly equal B A %in% B in A is an element of vector B If you want only those observations for a specific name (e.g., Mary), you use the equivalence operator ==. Note that you use double equal signs, not a single equal sign. filter(babynames, name == &quot;Mary&quot;) ## # A tibble: 268 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 ## 2 1880 M Mary 27 0.000228 ## 3 1881 F Mary 6919 0.0700 ## 4 1881 M Mary 29 0.000268 ## 5 1882 F Mary 8148 0.0704 ## 6 1882 M Mary 30 0.000246 ## 7 1883 F Mary 8012 0.0667 ## 8 1883 M Mary 32 0.000284 ## 9 1884 F Mary 9217 0.0670 ## 10 1884 M Mary 36 0.000293 ## # ... with 258 more rows If you wanted all the names except Mary, you use the ‘not equals’ operator: filter(babynames, name!=&quot;Mary&quot;) ## # A tibble: 1,924,397 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Anna 2604 0.0267 ## 2 1880 F Emma 2003 0.0205 ## 3 1880 F Elizabeth 1939 0.0199 ## 4 1880 F Minnie 1746 0.0179 ## 5 1880 F Margaret 1578 0.0162 ## 6 1880 F Ida 1472 0.0151 ## 7 1880 F Alice 1414 0.0145 ## 8 1880 F Bertha 1320 0.0135 ## 9 1880 F Sarah 1288 0.0132 ## 10 1880 F Annie 1258 0.0129 ## # ... with 1,924,387 more rows And if you wanted names from a defined set - e.g., names of British queens - you can use %in%: filter(babynames, name %in% c(&quot;Mary&quot;,&quot;Elizabeth&quot;,&quot;Victoria&quot;)) ## # A tibble: 772 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 ## 2 1880 F Elizabeth 1939 0.0199 ## 3 1880 F Victoria 93 0.000953 ## 4 1880 M Mary 27 0.000228 ## 5 1880 M Elizabeth 9 0.0000760 ## 6 1881 F Mary 6919 0.0700 ## 7 1881 F Elizabeth 1852 0.0187 ## 8 1881 F Victoria 117 0.00118 ## 9 1881 M Mary 29 0.000268 ## 10 1882 F Mary 8148 0.0704 ## # ... with 762 more rows This gives you data for the names in the vector on the right hand side of %in%. You can always invert an expression to get its opposite. So, for instance, if you instead wanted to get rid of all Marys, Elizabeths, and Victorias you would use the following: filter(babynames, !(name %in% c(&quot;Mary&quot;,&quot;Elizabeth&quot;,&quot;Victoria&quot;))) ## # A tibble: 1,923,893 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Anna 2604 0.0267 ## 2 1880 F Emma 2003 0.0205 ## 3 1880 F Minnie 1746 0.0179 ## 4 1880 F Margaret 1578 0.0162 ## 5 1880 F Ida 1472 0.0151 ## 6 1880 F Alice 1414 0.0145 ## 7 1880 F Bertha 1320 0.0135 ## 8 1880 F Sarah 1288 0.0132 ## 9 1880 F Annie 1258 0.0129 ## 10 1880 F Clara 1226 0.0126 ## # ... with 1,923,883 more rows You can include as many expressions as you like as additional arguments to filter() and it will only pull out the rows for which all of the expressions for that row evaluate to TRUE. For instance, filter(babynames, year &gt; 2000, prop &gt; .01) will pull out only those observations beyond the year 2000 that represent greater than 1% of the names for a given sex; any observation where either expression is false will be excluded. This ability to string together criteria makes filter() a very powerful member of the Wickham Six. Remember that this section exists. It will contain a lot of the answers to problems you face when wrangling data! 3.1.9 Activity 7: Creating new variables Sometimes we need to create a new variable that doesn’t exist in our dataset. For instance, we might want to figure out what decade a particular year belongs to. To create new variables, we use the function mutate(). Note that if you want to save this new column, you need to save it to an object. Here, you are mutating a new column and attaching it to the new_dat object you created in Activity 4. new_dat &lt;- mutate(.data = babynames, # the tibble you want to add a colum to decade = floor(year/10) *10) # new column name = what you want it to contain new_dat ## # A tibble: 1,924,665 x 6 ## year sex name n prop decade ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 1880 ## 2 1880 F Anna 2604 0.0267 1880 ## 3 1880 F Emma 2003 0.0205 1880 ## 4 1880 F Elizabeth 1939 0.0199 1880 ## 5 1880 F Minnie 1746 0.0179 1880 ## 6 1880 F Margaret 1578 0.0162 1880 ## 7 1880 F Ida 1472 0.0151 1880 ## 8 1880 F Alice 1414 0.0145 1880 ## 9 1880 F Bertha 1320 0.0135 1880 ## 10 1880 F Sarah 1288 0.0132 1880 ## # ... with 1,924,655 more rows In this case, you are creating a new column decade which has the decade each year appears in. This is calculated using the command decade = floor(year/10)*10. 3.1.10 Activity 8: Grouping and summarising Most quantitative analyses will require you to summarise your data somehow, for example, by calculating the mean, median or a sum total of your data. You can perform all of these operations using the function summarise(). First, let’s use the object dat that just has the data for the four girls names, Alexandra, Beverly, Emily, and Kathleen. To start off, we’re simply going to calculate the total number of babies across all years that were given one of these four names. It’s useful to get in the habit of translating your code into full sentences to make it easier to figure out what’s happening. You can read the below code as “run the function summarise using the data in the object dat to create a new variable named total that is the result of adding up all the numbers in the column n”. summarise(.data = dat, # the data you want to use total = sum(n)) # result = operation ## # A tibble: 1 x 1 ## total ## &lt;int&gt; ## 1 2161374 summarise() becomes even more powerful when combined with the final dplyr function, group_by(). Quite often, you will want to produce your summary statistics broken down by groups, for examples, the scores of participants in different conditions, or the reading time for native and non-native speakers. There are two ways you can use group_by(). First, you can create a new, grouped object. group_dat &lt;- group_by(.data = dat, # the data you want to group name) # the variable you want to group by If you look at this object in the viewer, it won’t look any different to the original dat, however, the underlying structure has changed. Let’s run the above summarise code again, but now using the grouped data. summarise(.data = group_dat, total = sum(n)) ## # A tibble: 4 x 2 ## name total ## &lt;chr&gt; &lt;int&gt; ## 1 Alexandra 231364 ## 2 Beverly 376914 ## 3 Emily 841491 ## 4 Kathleen 711605 summarise() has performed exactly the same operation as before - adding up the total number in the column n - but this time it has done is separately for each group, which in this case was the variable name. You can request multiple summary calculations to be performed in the same function. For example, the following code calculates the mean and median number of babies given each name every year. summarise(group_dat, mean_year = mean(n), median_year = median(n)) ## # A tibble: 4 x 3 ## name mean_year median_year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Alexandra 1977. 192 ## 2 Beverly 3089. 710. ## 3 Emily 6098. 1392. ## 4 Kathleen 5157. 3098 You can also add multiple grouping variables. For example, the following code groups new_dat by sex and decade and then calculates the summary statistics to give us the mean and median number of male and female babies in each decade. group_new_dat &lt;- group_by(new_dat, sex, decade) summarise(group_new_dat, mean_year = mean(n), median_year = median(n)) ## # A tibble: 28 x 4 ## # Groups: sex [2] ## sex decade mean_year median_year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 F 1880 111. 13 ## 2 F 1890 128. 13 ## 3 F 1900 131. 12 ## 4 F 1910 187. 12 ## 5 F 1920 211. 12 ## 6 F 1930 214. 12 ## 7 F 1940 262. 12 ## 8 F 1950 288. 13 ## 9 F 1960 235. 12 ## 10 F 1970 147. 11 ## # ... with 18 more rows 3.1.11 Activity 9: Pipes The final activity for this chapter essentially repeats what we’ve already covered but in a slightly different way. In the previous activities, you created new objects with new variables or groupings and then you called summarise() on those new objects in separate lines of code. As a result, you had multiple objects in your environment pane and you need to make sure that you keep track of the different names. Instead, you can use pipes. Pipes are written as %&gt;%and they should be read as “and then”. Pipes allow you to string together ‘sentences’ of code into ‘paragraphs’ so that you don’t need to create intermediary objects. Again, it is easier to show than tell. The below code does exactly the same as all the code we wrote above but it only creates one object. pipe_summary &lt;- mutate(babynames, decade = floor(year/10) *10) %&gt;% filter(name %in% c(&quot;Emily&quot;,&quot;Kathleen&quot;,&quot;Alexandra&quot;,&quot;Beverly&quot;), sex==&quot;F&quot;) %&gt;% group_by(name, decade) %&gt;% summarise(mean_decade = mean(n)) The reason that this function is called a pipe is because it ‘pipes’ the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes it will automatically take the data from the previous line of code so you don’t need to specify it again. When learning to code it can be a useful practice to read your code ‘out loud’ in full sentences to help you understand what it is doing. You can read the code above as “create a new variable called decade AND THEN only keep the names Emily, Kathleen, Alexandra and Beverly that belong to female babies AND THEN group the dataset by name and decade AND THEN calculate the mean number of babies with each name per decade.” Try doing this each time you write a new bit of code. Some people find pipes a bit tricky to understand from a conceptual point of view, however, it’s well worth learning to use them as when your code starts getting longer they are much more efficient and mean you have to write less code which is always a good thing! 3.1.11.1 Finished! That was a long pre-class but remember, you don’t need to memorise all of this code. You just need to know where to look for help. 3.2 In-class activities 3.2.1 Activity 1: Set-up Do the following. If you need help, consult the Lab 2 materials. Open R Studio and set the working directory to your Lab 3 folder. Ensure the environment is clear. Open the stub-3.2.Rmd file that you downloaded in the pre-class activities and ensure that the working directory is set to your Lab 3 folder and that the two .csv data files are in your working directory (you should see them in the file pane). Type and run the below code to load the tidyverse package and to load in the data files. library(tidyverse) dat &lt;- read_csv(&#39;ahi-cesd.csv&#39;) pinfo &lt;- read_csv(&#39;participant-info.csv&#39;) all_dat &lt;- inner_join(dat, pinfo, by= c(&quot;id&quot;, &quot;intervention&quot;) Now let’s start working with our tidyverse verb functions… 3.2.2 Activity 2: Select Select the columns all_dat, ahiTotal, cesdTotal, sex, age, educ, income, occasion, elapsed.days from the data and create a variable called summarydata. summarydata &lt;- select(all_dat, ahiTotal, cesdTotal, sex, age, educ, income, occasion, elapsed.days) Pause here and interpret the above code and output Discuss in pairs or groups how you would translate this code into English What columns have been removed from the data? 3.2.3 Activity 3: Arrange Arrange the data in the variable created above (summarydata) by ahiTotal with lowest score first. ahi_asc &lt;- arrange(summarydata, by = ahiTotal) How could you arrange this data in descending order (highest score first)? Solution arrange(summarydata, by = desc(ahiTotal)) What is the smallest ahiTotal score? What is the largest ahiTotal score? 3.2.4 Activity 4: Filter Filter the data ahi_desc by taking out those who are over 65 years of age. age_65max &lt;- filter(ahi_asc, age &lt; 65) What does filter() do? splits a column into multiple columns transforms existing columns takes multiple columns and collapses them together removes information that we are not interested in How many observations are left in age_65max after running filter()? 3.2.5 Activity 5: Summarise Then, use summarise to create a new variable data_median, which calculates the median ahiTotal score in this grouped data and assign it a table head called median_score. data_median &lt;- summarise(age_65max, median_score = median(ahiTotal)) What is the median score? Change the above code to give you the mean score. What is the mean score to 2 decimal places? Solution summarise(age_65max, mean_score = mean(ahiTotal)) 3.2.6 Activity 6: Group_by Group the data stored in the variable age_65max by sex, and store it in data_sex then use mutate to create a new column called Happiness which categorises participants based on whether they score above the median ahiTotal score for females. data_sex &lt;- group_by(age_65max, sex) happy_female &lt;- mutate(data_sex, Happiness_Female = (ahiTotal &gt; 74)) Pause here and interpret the above code and output What does group_by() do? provides summary statistics of an existing dataframe organises information in ascending or descending order transforms existing columns groups data frames based on a specific column so that all later operations are carried out on a group basis How would you change the code to group by education rathee than sex? Solution group_by(age_65max, educ) 3.2.7 Activity 7: Data visualisation Copy, paste and run the below code into a new code chunk to create a plot of depression scores grouped by income level using the age_65max data. ggplot(age_65max, aes(x = as.factor(income), y = cesdTotal, fill = as.factor(income))) + geom_violin(trim = FALSE, show.legend = FALSE, alpha = .6) + geom_boxplot(width = .2, show.legend = FALSE, alpha = .5) + scale_fill_viridis_d(option = &quot;D&quot;) + scale_x_discrete(name = &quot;Income Level&quot;, labels = c(&quot;Below Average&quot;, &quot;Average&quot;, &quot;Above Average&quot;)) + scale_y_continuous(name = &quot;Depression Score&quot;) Which income group has the highest median depression scores? Below Average Average Above Average Which group has the highest density of scores at any one point? Below Average Average Above Average Explain This Answer Density is represented by the curvy line around the boxplot that looks a little bit like a (drunk) violin. The fatter the violin, the more data points there are at any one point. This means that in the above plot, the Above Average group has the highest density because this has the widest violin, i.e., there are lots of people in the Above Average income group with a score of about 5. Is income group a between-subject or within-subject variable? Between-subjects Within-subjects Explain This Answer Between-subjects designs are where different participants are in different groups. Within-subject designs are when the same participants are in all groups. Income is an example of a between-subject variable because participants can only be in one grouping level of the independent variable 3.2.7.1 Finished! Well done! As a final step, try knitting the file to HTML. Remember to save your Markdown in your Lab 3 folder and make a note of any mistakes you made and how you fixed them. 3.3 Homework You can download all the R homework files and Assessment Information you need from the Lab Homework section of the Psych 1A Moodle. You should also begin to write your essay. "],
["a-lab-4.html", "4 1A: Lab 4 4.1 Pre-class activities 4.2 In-class activities 4.3 Homework", " 4 1A: Lab 4 4.1 Pre-class activities 4.1.1 Activity 1: dplyr recap In Lab 3 we were introduced to the tidyverse package, dplyr, and its six important functions. As a recap, which function(s) would you use to approach each of the following problems? We have a dataset of 400 adults, but we want to remove anyone with an age of 50 years or more. To do this, we could use the mutate() filter() group_by() summarise() select() arrange() function. We are interested in overall summary statistics for our data, such as the overall average and total number of observations. To do this, we could use the summarise() arrange() mutate() group_by() select() filter() function. Our dataset has a column with the number of cats a person has, and a column with the number of dogs. We want to calculate a new column which contains the total number of pets each participant has. To do this, we could use the filter() mutate() arrange() group_by() select() summarise() function. We want to calculate the average for each participant in our dataset. To do this we could use the arrange() and mutate() group_by() and summarise() group_by() and arrange() filter() and select() functions. We want to order a dataframe of participants by the number of cats that they own, but want our new dataframe to only contain some of our columns. To do this we could use the mutate() and filter() group_by() and mutate() arrange() and select() select() and summarise() functions. 4.1.2 Data visualisation As Grolemund and Wickham tell us: Visualisation is a fundamentally human activity. A good visualisation will show you things that you did not expect, or raise new questions about the data. A good visualisation might also hint that you’re asking the wrong question, or you need to collect different data. Visualisations can surprise you, but don’t scale particularly well because they require a human to interpret them. ``` (http://r4ds.had.co.nz/introduction.html) Being able to visualise our variables, and relationships between our variables, is a very useful skill. Before we do any statistical analyses or present any summary statistics, we should visualising our data as it is: A quick and easy way to check our data make sense, and to identify any unusual trends. A way to honestly present the features of our data to anyone who reads our research. ggplot() builds plots by combining layers (see Figure 4.1)). If you’re used to making plots in Excel this might seem a bit odd at first, however, it means that you can customise each layer and R is capable of making very complex and beautiful figures (this website gives you a good sense of what’s possible). Figure 4.1: ggplot2 layers from Field et al. (2012) 4.1.3 Activity 2: Set-up We’re going to use the data from the Labs to explain how ggplot2 works so let’s do the set-up as usual. Open R Studio and ensure the environment is clear. Download the lab 4 files, extract the files and then move them in to your Lab 3 folder. Open the stub-4.1.Rmd file that you downloaded in the pre-class activities and ensure that the working directory is set to your Lab 4 folder and that the two .csv data files are in your working directory (you should see them in the file pane). Type and run the below code to load the tidyverse package and to load in the data files in to the Actvity 1 code chunk. library(tidyverse) dat &lt;- read_csv(&#39;ahi-cesd.csv&#39;) pinfo &lt;- read_csv(&#39;participant-info.csv&#39;) all_dat &lt;- inner_join(dat, pinfo, by= c(&quot;id&quot;, &quot;intervention&quot;) summarydata &lt;- select(.data = all_dat, ahiTotal, cesdTotal, sex, age, educ, income, occasion,elapsed.days) 4.1.4 Activity 3: Factors Before we go any further we need to perform an additional step of data processing that we have glossed over to this point. First, run the below code to look at the structure of the dataset: str(summarydata) ## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 992 obs. of 8 variables: ## $ ahiTotal : num 32 34 34 35 36 37 38 38 38 38 ... ## $ cesdTotal : num 50 49 47 41 36 35 50 55 47 39 ... ## $ sex : num 1 1 1 1 1 1 2 1 2 2 ... ## $ age : num 46 37 37 19 40 49 42 57 41 41 ... ## $ educ : num 4 3 3 2 5 4 4 4 4 4 ... ## $ income : num 3 2 2 1 2 1 1 2 1 1 ... ## $ occasion : num 5 2 3 0 5 0 2 2 2 4 ... ## $ elapsed.days: num 182 14.2 33 0 202.1 ... R assumes that all of the variables are numeric (represented by num) and this is going to be a problem because whilst sex, educ, and income are represented by numerical codes, they aren’t actually numbers, they’re categories, or factors. We need to tell R that these variables are factors and we can use mutate() to do this by overriding the original variable with the same data but classified as a factor. Type and run the below code to change the categories to factors. summarydata &lt;- summarydata %&gt;% mutate(sex = as.factor(sex), educ = as.factor(educ), income = as.factor(income)) Remember this. It’s a really important step and if your graphs are looking weird this might be the reason. 4.1.5 Activity 4: Bar plot For our first example we will recreate the bar plot showing the number of males and females from Lab 2 by showing you how the layers of code build up. The first line (or layer) sets up the base of the graph: the data to use and the aesthetics (what will go on the x and y axis, how the plot will be grouped). aes() can take both an x and y argument, however, with a bar plot you are just asking R to count the number of data points in each group so you don’t need to specify this. ggplot(summarydata, aes(x = sex)) Figure 4.2: First ggplot layer sets the axes The next layer adds a geom or a shape, in this case we use geom_bar() as we want to draw a bar plot. ggplot(summarydata, aes(x = sex)) + geom_bar() Figure 1.1: Basic barplot Adding fill to the first layer will separate the data into each level of the grouping variable and give it a different colour. In this case, there is a different coloured bar for each level of sex. ggplot(summarydata, aes(x = sex, fill = sex)) + geom_bar() Figure 4.3: Barplot with colour fill() has also produced a plot legend to the right of the graph. When you have multiple grouping variables you need this to know which groups each bit of the plot is referring to, but in this case it is redundant because it doesn’t tell us anything that the axis labels don’t already. We can get rid of it by adding show.legend = FALSE to the geom_bar() code. ggplot(summarydata, aes(x = sex, fill = sex)) + geom_bar(show.legend = FALSE) Figure 4.4: Barplot without legend We might want to tidy up our plot to make it look a bit nicer. First we can edit the axis labels to be more informative. The most common functions you will use are: scale_x_continuous() for adjusting the x-axis for a continuous variable scale_y_continuous() for adjusting the y-axis for a continuous variable scale_x_discrete() for adjusting the x-axis for a discrete/categorical variable scale_y_discrete() for adjusting the y-axis for a discrete/categorical variable And in those functions the two most common arguments you will use are: name which controls the name of each axis labels which controls the names of the break points on the axis There are lots more ways you can customise your axes but we’ll stick with these for now. Copy, paste, and run the below code to change the axis labels and change the numeric sex codes into words. ggplot(summarydata, aes(x = sex, fill = sex)) + geom_bar(show.legend = FALSE) + scale_x_discrete(name = &quot;Participant Sex&quot;, labels = c(&quot;Female&quot;, &quot;Male&quot;)) + scale_y_continuous(name = &quot;Number of participants&quot;) Figure 4.5: Barplot with axis labels Second, you might want to adjust the colours and the visual style of the plot. ggplot2 comes with built in themes. Below, we’ll use theme_minimal() but try typing theme_ into a code chunk and try all the options that come up to see which one you like best. ggplot(summarydata, aes(x = sex, fill = sex)) + geom_bar(show.legend = FALSE) + scale_x_discrete(name = &quot;Participant Sex&quot;, labels = c(&quot;Female&quot;, &quot;Male&quot;)) + scale_y_continuous(name = &quot;Number of participants&quot;) + theme_minimal() Figure 4.6: Barplot with minimal theme There are various options to adjust the colours but a good way to be inclusive is to use a colour-blind friendly palette that can also be read if printed in black-and-white. To do this, we can add on the function scale_fill_viridis_d(). This function has 5 colour options, A, B, C, D, and E. I prefer E but you can play around with them and choose the one you prefer. ggplot(summarydata, aes(x = sex, fill = sex)) + geom_bar(show.legend = FALSE) + scale_x_discrete(name = &quot;Participant Sex&quot;, labels = c(&quot;Female&quot;, &quot;Male&quot;)) + scale_y_continuous(name = &quot;Number of participants&quot;) + theme_minimal() + scale_fill_viridis_d(option = &quot;E&quot;) Figure 4.7: Barplot with colour-blind friendly colour scheme Finally, you can also adjust the transparency of the bars by adding alpha to geom_bar(). Play around with the value and see what value you prefer. ggplot(summarydata, aes(x = sex, fill = sex)) + geom_bar(show.legend = FALSE, alpha = .8) + scale_x_discrete(name = &quot;Participant Sex&quot;, labels = c(&quot;Female&quot;, &quot;Male&quot;)) + scale_y_continuous(name = &quot;Number of participants&quot;) + theme_minimal() + scale_fill_viridis_d(option = &quot;E&quot;) Figure 4.8: Barplot with adjusted alpha 4.1.6 Layers The key thing to note in the above examples is the use of layers. Whilst we’ve built this up step-by-step, they are independent and you could remove any of them except for the first layer Copy, paste and run the below code to produce a bar graph that shows the number of female and male participants in the dataset. In R terms, ggplot2 is a fairly old package. As a result, the use of pipes wasn’t included when it was originally written. As you can see in the code above, the layers of the code are separated by + rather than %&gt;%. In this case, + is doing essentially the same job as a pipe - be careful not to confuse them. 4.1.7 Activity 5: Violin-boxplot As our final activity we will also explain the code used to create the violin-boxplot from Lab 2, hopefully now you will be able to see how similar it is in structure to the bar chart code. In fact, there are only three differences: We have added a y argument to the first layer because we wanted to represent two variables, not just a count. geom_violin() has an additional argument trim. Try setting this to TRUE to see what happens. geom_boxpot() has an additional argument width. Try adjusting the value of this and see what happens. ggplot(summarydata, aes(x = income, y = ahiTotal, fill = income)) + geom_violin(trim = FALSE, show.legend = FALSE, alpha = .4) + geom_boxplot(width = .2, show.legend = FALSE, alpha = .7)+ scale_x_discrete(name = &quot;Income&quot;, labels = c(&quot;Below Average&quot;, &quot;Average&quot;, &quot;Above Average&quot;)) + scale_y_continuous(name = &quot;Authentic Happiness Inventory Score&quot;)+ theme_minimal() + scale_fill_viridis_d() Figure 4.9: Violin-boxplot 4.1.8 Activity 6: Layers part 2 The final thing to note about the use of layers in ggplot2 is that although they are independent, the order you put them in does matter. Try running the two code examples below and see what happens. ggplot(summarydata, aes(x = income, y = ahiTotal)) + geom_violin() + geom_boxplot() ggplot(summarydata, aes(x = income, y = ahiTotal)) + geom_boxplot() + geom_violin() 4.1.8.1 Finished! Well done! ggplot can be a bit difficult to get your head around at first, particularly if you’ve been used to making graphs a different way. But once it clicks, you’ll be able to make informative and professional visualisations with ease, which, amongst other things, will make your reports look FANCY. 4.2 In-class activities 4.2.1 Getting the data ready to work with Today in the lab we will be working with our data to generate a plot of two variables from the Woodworth et al. dataset. Before we get to generate our plot, we still need to work through the steps to get the data in the shape we need it to be in for our particular question. In particular we need to generate the object summarydata that just has the variable we need.You have done these steps before so go back to the relevant Lab and use that to guide you through. 4.2.2 Activity 1: Set-up Download stub-4.2.Rmd in to your Lab 4 folder. Make sure that you save the file THEN open it. If you just open the file without saving things will go wrong. Open R Studio and ensure the environment is clear. Open the Markdown stub file and ensure that your working directory is set to your Lab 4 folder. Look through your previous work to find the code that loads the tidyverse, reads in the data files and creates an object called all_dat that joins the two objects dat and pinfo. 4.2.3 Activity 2: Select Select the columns all_dat, ahiTotal, cesdTotal, sex, age, educ, income, occasion, elapsed.days from the data and create an object named variable summarydata. 4.2.4 Activity 3: Arrange Arrange the data in the variable created above (summarydata) by ahiTotal with lowest score first and save it in an object named ahi_asc. 4.2.5 Activity 4:Filter Filter the data ahi_asc by only keeping those who are 65 years old or younger and save it in an object named age_65max. 4.2.6 Activity 5: Group and summarise First, calculate the overall median ahiTotal score for all participants (hint: use summarise()) and save it in an object called median_score. Then, group the data stored in the variable age_65max by sex, and store it in data_sex. Then, use summarise to create a new variable sex_median, which calculates the median ahiTotal score for each sex in this grouped data and assign it a table head called median_score. (Hint: if you’re stuck, see this dplyr documentation). 4.2.7 Activity 6: Mutate Use mutate() to create a new column in data_sex called Happiness which categorises participants based on whether they score above or below the overall median ahiTotal score (i.e., the median score for all participants, not grouped by sex). 4.2.8 Activity 7: Scatterplots In order to visualise two continuous variables, we can use a scatterplot. Using the ggplot code you learned about in the pre-class activities, try and recreate the below plot. A few hints: Use the age_65max data. Put ahiTotal on the x-axis and cesdTotal on the y-axis. Rather than using geom_bar(), geom_violin(), or geom_boxplot(), for a scatteplot you need to use geom_point(). Rather than using scale_fill_viridis_d() to change the colour, add the argument colour = \"red\" to geom_point (except replace “red” with whatever colour you’d prefer). Remember to edit the axis names. Figure 4.10: Scatterplot of happiness and depression scores How would you describe the relationship between the two variables? As happiness scores increase, depression scores increase As happiness score increase, depression scores decrease As happiness scores decrease, depression scores decrease 4.2.8.1 Finished! Great job! You have now worked with the essential basics of good practice in data wrangling! In Psych 1B we will continue using these wrangling skills on new data and also data that you collect yourself. 4.2.9 Activity solutions 4.2.9.1 Activity 1 Solution library(tidyverse) dat &lt;- read_csv (&#39;ahi-cesd.csv&#39;) pinfo &lt;- read_csv(&#39;participant-info.csv&#39;) all_dat &lt;- inner_join(dat, pinfo, by=c(&quot;id&quot;, &quot;intervention&quot;) 4.2.9.2 Activity 2 Solution summarydata &lt;- select(all_dat, ahiTotal, cesdTotal, sex, age, educ, income, occasion, elapsed.days) 4.2.9.3 Activity 3 Solution ahi_asc &lt;- arrange(summarydata, by = ahiTotal) 4.2.9.4 Activity 4 Solution age_65max &lt;- filter(ahi_asc, age &lt;= 65) 4.2.9.5 Activity 5 Solution median_score &lt;- summarise(age_65max, median = median(ahiTotal)) data_sex &lt;- group_by(age_65max, sex) data_median &lt;- summarise(data_sex, median_score = median(ahiTotal)) 4.2.9.6 Activity 6 Solution happy &lt;- mutate(data_sex, Happiness = (ahiTotal &gt; 73)) 4.2.9.7 Activity 7 Solution ggplot(age_65max, aes(x = ahiTotal , y = cesdTotal)) + geom_point(colour = &quot;red&quot;) + scale_x_continuous(name = &quot;Happiness Score&quot;) + scale_y_continuous(name = &quot;Depression Score&quot;) + theme_minimal() 4.3 Homework You can download all the R homework files and Assessment Information you need from the Lab Homework section of the Psych 1A Moodle. "]
]
